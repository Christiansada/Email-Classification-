{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOue-EhLJ2Xe"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "\n",
        "data = pd.read_csv(\"SPAM text message 20170820 - Data.csv\")\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "    return text\n",
        "\n",
        "# Apply the preprocessing function to the 'Message' column\n",
        "data['Message'] = data['Message'].apply(preprocess_text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Tokenization and Padding Sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['Message'])\n",
        "sequences = tokenizer.texts_to_sequences(data['Message'])\n",
        "padded_sequences = pad_sequences(sequences, padding='post')\n",
        "\n",
        "# Prepare the Labels\n",
        "labels = np.array(data['Category'].map({'ham': 0, 'spam': 1}))\n",
        "\n"
      ],
      "metadata": {
        "id": "Y3EK1CuBKPSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the LSTM Model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 16\n",
        "max_length = len(max(padded_sequences, key=len))\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the Model Summary (Architecture)\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5O7F-IZKY1R",
        "outputId": "2c767742-764c-4c4b-8673-19290896c1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 171, 16)           154528    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                6272      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,833\n",
            "Trainable params: 160,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the Model on the Testing Data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print the Test Accuracy\n",
        "print(\"\\nTest Accuracy: {:.4f}\".format(test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BZIKIqUKkXB",
        "outputId": "f9dbcf3d-1f69-48c5-c88d-ef4a5859d872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "112/112 [==============================] - 14s 95ms/step - loss: 0.4452 - accuracy: 0.8522 - val_loss: 0.4097 - val_accuracy: 0.8576\n",
            "Epoch 2/10\n",
            "112/112 [==============================] - 11s 96ms/step - loss: 0.3918 - accuracy: 0.8679 - val_loss: 0.4096 - val_accuracy: 0.8576\n",
            "Epoch 3/10\n",
            "112/112 [==============================] - 9s 81ms/step - loss: 0.3920 - accuracy: 0.8679 - val_loss: 0.4109 - val_accuracy: 0.8576\n",
            "Epoch 4/10\n",
            "112/112 [==============================] - 10s 91ms/step - loss: 0.3910 - accuracy: 0.8679 - val_loss: 0.4093 - val_accuracy: 0.8576\n",
            "Epoch 5/10\n",
            "112/112 [==============================] - 10s 92ms/step - loss: 0.3914 - accuracy: 0.8679 - val_loss: 0.4101 - val_accuracy: 0.8576\n",
            "Epoch 6/10\n",
            "112/112 [==============================] - 10s 88ms/step - loss: 0.3916 - accuracy: 0.8679 - val_loss: 0.4093 - val_accuracy: 0.8576\n",
            "Epoch 7/10\n",
            "112/112 [==============================] - 9s 81ms/step - loss: 0.3915 - accuracy: 0.8679 - val_loss: 0.4093 - val_accuracy: 0.8576\n",
            "Epoch 8/10\n",
            "112/112 [==============================] - 10s 92ms/step - loss: 0.3921 - accuracy: 0.8679 - val_loss: 0.4110 - val_accuracy: 0.8576\n",
            "Epoch 9/10\n",
            "112/112 [==============================] - 10s 93ms/step - loss: 0.3910 - accuracy: 0.8679 - val_loss: 0.4093 - val_accuracy: 0.8576\n",
            "Epoch 10/10\n",
            "112/112 [==============================] - 10s 91ms/step - loss: 0.3908 - accuracy: 0.8679 - val_loss: 0.4111 - val_accuracy: 0.8576\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.3939 - accuracy: 0.8664\n",
            "\n",
            "Test Accuracy: 0.8664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7v7v4G1PKsmp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}